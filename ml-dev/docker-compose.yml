

services:
  # ML Development Environment with GPU Support
  ml-dev:
    build:
      context: ./ml-dev
      dockerfile: Dockerfile
    container_name: ml-dev
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - H2O_XGB_BACKEND=external-gpu
    volumes:
      - ./ml-dev/notebooks:/workspace/notebooks
      - ./ml-dev/venvs:/workspace/venvs
      - ./ml-dev/data:/workspace/data
      - ./ml-dev/models:/workspace/models
      - ./ml-dev/code:/workspace/code
    ports:
      - "8888:8888"  # For Jupyter
    networks:
      - ml-network
    deploy:
      resources:
        limits:
          memory: 16G
    restart: unless-stopped

  # Backend Service (FastAPI and H2O)
  backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile
    image: e2e-automl-backend:latest
    container_name: automl-backend
    ports:
      - "8000:8000"
      - "54321:54321"
    volumes:
      - ./backend:/app 
      - ./backend/data:/app/data
      - ./mlflow/artifacts:/mlflow/artifacts
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - H2O_XGB_BACKEND=external-gpu
      - UVICORN_RELOAD=true  
      - UVICORN_RELOAD_DIRS=/app  
      - H2O_PORT=54321
      - MLFLOW_TRACKING_URI=http://192.168.2.222:5000
      - MLFLOW_ARTIFACT_ROOT=/mlflow/artifacts
      - DATABASE_URL=postgresql://mlflow:mlflow-pass@db/mlflow_db
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - ml-network
    depends_on:
      - db
      - mlflow

  # Frontend Service (Streamlit UI)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    image: e2e-automl-frontend:latest
    container_name: automl-frontend
    ports:
      - "8501:8501"
    volumes:
      - ./frontend:/app
      - ./frontend/data:/app/data
    environment:
      - BACKEND_URL=http://192.168.2.222:8000
      - MLFLOW_TRACKING_URL=http://192.168.2.222:5000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - ml-network

  # MLflow with PostgreSQL backend
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.10.1
    container_name: mlflow
    command: [
      "sh", "-c",
      "apt-get update && apt-get install -y curl && pip install psycopg2-binary && mlflow server --backend-store-uri postgresql://mlflow:mlflow-pass@db/mlflow_db --default-artifact-root /mlflow/artifacts --host 0.0.0.0"
    ]
    ports:
      - "5000:5000"
    volumes:
      - ./mlflow/artifacts:/mlflow/artifacts
    networks:
      - ml-network
    depends_on:
      db:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL Database
  db:
    image: postgres:15-alpine
    container_name: postgres-db
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow-pass
      POSTGRES_DB: mlflow_db
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
    networks:
      - ml-network
    restart: unless-stopped
    ports:
      - "5432:5432"
    healthcheck: 
      test: ["CMD-SHELL", "pg_isready -U mlflow -d mlflow_db"]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 2G

  # pgAdmin for Database Management
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@mlflow.com
      PGADMIN_DEFAULT_PASSWORD: pgadmin-pass
    volumes:
      - ./pgadmin_data:/var/lib/pgadmin
    networks:
      - ml-network
    restart: unless-stopped
    ports:
      - "8080:80"
    depends_on:
      - db

  # Monitoring with Prometheus and Grafana
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"
    networks:
      - ml-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    volumes:
      - ./grafana/data:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - ml-network
    depends_on:
      - prometheus
    restart: unless-stopped

networks:
  ml-network:
    driver: bridge
